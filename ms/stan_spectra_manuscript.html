<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.245">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jeff Wesner">
<meta name="dcterms.date" content="2022-08-20">

<title>bayes_spectra</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="stan_spectra_manuscript_files/libs/clipboard/clipboard.min.js"></script>
<script src="stan_spectra_manuscript_files/libs/quarto-html/quarto.js"></script>
<script src="stan_spectra_manuscript_files/libs/quarto-html/popper.min.js"></script>
<script src="stan_spectra_manuscript_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="stan_spectra_manuscript_files/libs/quarto-html/anchor.min.js"></script>
<link href="stan_spectra_manuscript_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="stan_spectra_manuscript_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="stan_spectra_manuscript_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="stan_spectra_manuscript_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="stan_spectra_manuscript_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">bayes_spectra</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Jeff Wesner </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">August 20, 2022</p>
    </div>
  </div>
    
  </div>
  

</header>

<p><strong>A Bayesian hierarchical model for size spectra</strong></p>
<p>Jeff S. Wesner, Justin P.F. Pomeranz, Jim Junker, Vosjava Gjoni</p>
<p>University of South Dakota, Department of Biology, Vermillion, SD 57069</p>
<p>Colorado Mesa University</p>
<p>Louisiana University Marine Consortium</p>
<p><a href="mailto:Jeff.Wesner@usd.edu" class="email">Jeff.Wesner@usd.edu</a></p>
<div style="page-break-after: always;"></div>
<p><strong>Abstract</strong></p>
<p>Keywords: <em>Bayesian, body size spectra, pareto</em></p>
<div style="page-break-after: always;"></div>
<p><strong>Introduction</strong></p>
<p>The distribution of individual body sizes in an ecosystem is approximated by a bounded power law with a single free parameter <em>b</em>, corresponding to the following probability density function (Edwards et al.&nbsp;2020):</p>
<p><span id="eq-1"><span class="math display">\[
f(x) = Cx^b, x_{min} &lt;= x &gt;= x_{max}
\tag{1}\]</span></span></p>
<p>where x is the body size (e.g., mass or volume) of an individual in the community collected out of <strong>X</strong> total individuals, regardless of taxon. <em>xmin</em> is the smallest individual in the collection <strong>X</strong> and <em>xmax</em> is the largest individuual. <em>C</em> is a constant equal to:</p>
<p><span class="math display">\[
C = \frac{b + 1}{{x_{max}^{b+1}} - {x_{min}^{b+1}}}, \text{when b is not} -1
\]</span></p>
<p>or</p>
<p><span class="math display">\[
C = \frac{1}{{logx_{max}^{b+1}} - {logx_{min}^{b+1}}}, \text{when b is} -1
\]</span></p>
<p>This model is also known as the bounded power law or truncated Pareto distrubution. The terms “bounded” or “truncated” refer to the limits of <em>xmin</em> and <em>xmax</em>. Without those limits, the function is a simple power law. Each term in the equations above comes directly from the data except for the exponent <em>b</em>. It is the only free parameter in this model and needs to be estimated with a statistical model. By comparison, in a Gaussian model there are two free parameters that need statistical estimation, the mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>.</p>
<p>To fit this model requires a single column of data in which each data point is a single measure of the body size of an individual. As long as the body sizes are collected systematically and without bias towards certain taxa or phenotypes, there is no need to know any more ecological information about the data points (e.g., taxon, trophic position, age, abundance, etc.). The aim of the model is to estimate <em>b</em>, which quantifies the relative frequency of large to small body sizes in the community. For example, a <em>b</em> value of -2.4 would be “steeper” than a <em>b</em> value of -1.4. That indicates that the community with -2.4 has a higher abundance of small individuals relative to large individuals than the community with -1.4. <em>b</em> is unitless, but caries with it important ecological information. In size-structured aquatic ecosystems, the relative abundance of small to large individuals is governed, in part, by trophic efficiency, helping to explain why large organisms are less abundant than small organisms. In other words, changes in <em>b</em> among space and time can indicate changes in energy flux through the food web, assuming constant resource supply and no allochthonous subsidies.</p>
<p>One source of confusion when fitting individual size distributions (ISD) that there is no term for abundance. This is confusing because the theoretical predictions for body size distributions rely on the assumption that large organisms are less <em>abundant</em> than small organisms. It seems natural to include data on abundance, though it is not needed to fit an ISD. Nevertheless, most methods for estimating the parameter <em>b</em> include an abundance estimate. However, that estimate comes at the cost of binning, and the methods for binning vary widely among studies, creating confusion in the literature (Edwards et al.&nbsp;2017). In most cases, all organisms in a given size range, such as 10-100 grams dry mass) are lumped into a single bin. Then the abundance of organisms in that bin is tallied, giving the two desired measures, abundance and body size. These data are then fit using log-log regressions with a Gaussian likelihood, and the slope of that regression is assumed to represent the <em>b</em> exponent of a power law.</p>
<p>The benefit of the binning approach is that <em>b</em> can be estimated from a simple linear regression model, which ecologists are familiar with. However, binning also condenses a wide range of body sizes into a single bin. For example, their may be 500 individual body sizes between 10-100 grams, but when those are binned into a midpoint of, say 45, all of the variation in these sizes is removed. In essence, binning changes the analysis so that it is no longer measuring the ISD (White et al.&nbsp;2007, Edwards et al.&nbsp;2017). The resulting estimates of <em>b</em> can differ widely from the true value that the models intend to estimate, sometimes even being a different sign (Edwards et al.&nbsp;2017, Pomeranz et al.&nbsp;<em>in prep</em>).</p>
<p>An improved alternative to binning and linear regression is to fit the body size data to a power law probability distribution directly (White et al.&nbsp;2007, Edwards et al.&nbsp;2017/2020). This method uses all of the data without binning and directly estimates the parameter of interest, <em>b.</em> Edwards et al.&nbsp;(2017/2020) published the likelihood for a bounded power law that estimates <em>b</em>, including an alternative that accounts for data that are not strictly continuous, such as weights rounded to the first decimal. These methods are well documented in the <em>sizeSpectra</em> package in R. However, it is only possible to fit the models to single dataset using maximum likelihood. To our knowledge there is no current method to fit ISD models to multiple groups of ISD’s, such as data collected from multiple sites or multiple years.</p>
<p>Here, we expand the model of Edwards et al.&nbsp;(2020) so that it can include both fixed and random predictor variables. The model allows for a flexible hierarchical structure within the modeling language Stan.</p>
<p><strong>Methods</strong></p>
<p>Edwards et al.&nbsp;(2020) derived the likelihood equation for a bounded power for data that include density estimates for each body size. These data are technically binned, but only to the extend that the body size measures are rounded. In other words, if two individuals are measured as 0.25 mgDM, then they are added up so that the data included a mass of 0.25 and a density of 2 per unit area. The advantage of this is that any estimated body size collection can be combined so long as there is an areal estimate of its density. For example, fish collected with 3-pass removal and insects collected with a surber sample could be combined into a single data set by converting each body mass to mass per unit area. The resulting data set contains a column for each measured body size, a column for the density of those body sizes, and any other identifying data that could be used for fixed or random effects.</p>
<p>The resulting model has a log probability density of:</p>
<p><span class="math display">\[
counts*\log(\frac{b+1}{x_{max}^{b+1} - x_{min}^{b+1}}) + b*\log x, \text{when b is not -1}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
counts*\log(\log x_{min} - \log x_{max}) + b*\log x, \text{when b = -1}
\]</span></p>
<p>where <span class="math inline">\(x\)</span> is an individual body size, <span class="math inline">\(x_{min}\)</span> and <span class="math inline">\(x_{max}\)</span> are the minimum and maximum measurements in the dataset. If there are multiple samples, then each sample will have its own <span class="math inline">\(x_{min}\)</span> and <span class="math inline">\(x_{max}\)</span>. <span class="math inline">\(counts\)</span> is the density or abundance of a given body mass value and <span class="math inline">\(log\)</span> is natural log. We call this PDF the <em>paretocounts</em> distribution.</p>
<p>Given the <em>paretocounts</em> distribution, we can estimate <span class="math inline">\(b\)</span> from a single dataset using the following model:</p>
<p><span class="math display">\[
x_i \sim paretocounts(b, x_{min}, x_{max}, counts)
\]</span></p>
<p><span class="math display">\[
b = \alpha
\]</span></p>
<p><span class="math display">\[
\alpha \sim Normal(\mu, \sigma)
\]</span></p>
<p>The first line is the likelihood, the second line is the linear model , and the third line contains the priors. We can expand the second line to include linear predictors and random effects.</p>
<p>To test the performance of the model, we first fit data simulated from a bounded power law and attempted to recover the parameter values for <span class="math inline">\(b\)</span>. Next we fit a model to data from NEON that contained 23 sites collected multiple times in each of 5 years. The data contained 22,707 measurements of fish and invertebrate dry mass collected by NEON. The second model contained varying intercepts (aka random effects) for year and site along with a predictor variable of mean annual water temperature. It contained the following model structure.</p>
<p><span class="math display">\[
x_{i,j,k} \sim paretocounts(b, x_{min_{j,k}}, x_{max_{j,k}}, counts_{j,k})
\]</span></p>
<p><span class="math display">\[
b = \alpha + \beta mat_s + \alpha_{site} + \alpha_{year}
\]</span></p>
<p><span class="math display">\[
\alpha \sim Normal(-1.5, 0.2)
\]</span></p>
<p><span class="math display">\[
\beta \sim Normal(0, 0.1)
\]</span></p>
<p><span class="math display">\[
\alpha_{site} \sim Normal(0, \sigma_{site})
\]</span></p>
<p><span class="math display">\[\alpha_{year} \sim Normal(0, \sigma_{year})
\]</span></p>
<p><span class="math display">\[
\sigma_{site} \sim Exponential(9)
\]</span></p>
<p><span class="math display">\[
\sigma_{year} \sim Exponential(9)
\]</span></p>
<p>Where <span class="math inline">\(x_{i,j,k}\)</span> is a measure of the <span class="math inline">\(i\)</span>th dry mass (mg) from the <span class="math inline">\(j\)</span>th site on the <span class="math inline">\(k\)</span>th date, and similarly for <span class="math inline">\(x_{min}\)</span>,<span class="math inline">\(x_{max}\)</span>, and <span class="math inline">\(counts\)</span>. Here, <span class="math inline">\(counts\)</span> reflects a density estimate in units of number per square meter (no_m2). <span class="math inline">\(\alpha\)</span> is the intercept, <span class="math inline">\(\beta\)</span> is the slope relating the ISD exponent <span class="math inline">\(b\)</span> to standardized mean annual stream temperature <span class="math inline">\(mat_s\)</span>, and <span class="math inline">\(\alpha_{site}\)</span> and <span class="math inline">\(\alpha_{year}\)</span> are varying intercepts for site and year with mean offsets of 0 and a standard deviation equal to <span class="math inline">\(\sigma_{site}\)</span> and <span class="math inline">\(\sigma_{year}\)</span>.</p>
<p>A snippet of the dataset is below, with <span class="math inline">\(x\)</span> represented by the column <em>dw</em> in units of milligrams of dry mass and <span class="math inline">\(counts\)</span> represented by <em>no_m2</em>, the density of a given dry mass for each collection. Notice that <em>xmin</em> and <em>xmax</em> vary among sites.</p>
<div class="cell" data-paged.print="false">
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 7
      dw no_m2  mat_s  year  site   xmin   xmax
   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;
1 0.0001     8 -1.57   2017     5 0.0001 52885.
2 0.0001     4 -1.55   2019    16 0.0001 90302.
3 0.0001    22 -1.33   2018    23 0.0001 13160.
4 0.0001    11 -1.33   2018    23 0.0001 15993.
5 0.0001   105 -0.808  2016    19 0.0001 37044.
6 0.0001   167 -0.313  2017     8 0.0001 14204.</code></pre>
</div>
</div>
<p>The full dataset has 22,707 rows of data. The model uses these data to estimate the value of <span class="math inline">\(b\)</span> along with its relation to mean annual temperature. In addition, by including the varying intercepts, the model estimates account for repeated sampling among sites through partial pooling. This makes estimates of <span class="math inline">\(b\)</span> more conservative and less influenced by outliers. The model results in estimates of the overall average <span class="math inline">\(b\)</span> via the intercept, a slope with temperature <span class="math inline">\(\beta\)</span>, and individual partially pooled estimates of site-specific and year-specific <span class="math inline">\(b\)</span>. Finally, the <span class="math inline">\(\sigma_{site}\)</span> and <span class="math inline">\(\sigma_{year}\)</span> values can be used to predict <span class="math inline">\(b\)</span> in future sites and future years via the posterior predictive distributions.</p>
<p>We fit the model in <em>rstan</em> (Stan Development Team 2022) using 4000 iterations of 4 chains. Model convergence was checked by ensuring that all r-hats were &lt;1.1. Prior values were determined using prior predictive simulation with values similar to those from Pomeranz et al.&nbsp;(2021). To ensure that the model likelihood was translated correctly from Edwards et al.&nbsp;(2020), we compared estimates of <span class="math inline">\(b\)</span> using <em>paretocounts</em> with maximum likelihood estimates produced from the <em>sizeSpectra</em> package. Results were identical when run individually on single sites, indicating that the log probability distribution was correctly translated from <em>sizeSpectra</em> to <em>Stan.</em></p>
<p><strong>Results</strong></p>
<p><em>Runtime</em></p>
<p>With 4000 iterations and 4 chains, the model took ~ 9.3 hours to run using multiple cores on the University of South Dakota’s computing cluster (Lawrence).</p>
<p><em>Model Convergence</em></p>
<p>The traceplot below shows good convergence. Only the first 10 parameters are shown, but all had Rhats &lt;1.01.</p>
<div class="cell" data-paged.print="false">
<div class="cell-output-display">
<p><img src="stan_spectra_manuscript_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell" data-paged.print="false">
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 34 × 2
   parameter           Rhat
   &lt;chr&gt;              &lt;dbl&gt;
 1 beta                1.00
 2 a                   1.01
 3 alpha_raw_year[1]   1.00
 4 alpha_raw_year[2]   1.01
 5 alpha_raw_year[3]   1.00
 6 alpha_raw_year[4]   1.00
 7 alpha_raw_year[5]   1.01
 8 alpha_raw_year[6]   1.01
 9 alpha_raw_site[1]   1.00
10 alpha_raw_site[2]   1.00
11 alpha_raw_site[3]   1.00
12 alpha_raw_site[4]   1.00
13 alpha_raw_site[5]   1.00
14 alpha_raw_site[6]   1.00
15 alpha_raw_site[7]   1.00
16 alpha_raw_site[8]   1.00
17 alpha_raw_site[9]   1.00
18 alpha_raw_site[10]  1.00
19 alpha_raw_site[11]  1.00
20 alpha_raw_site[12]  1.00
21 alpha_raw_site[13]  1.00
22 alpha_raw_site[14]  1.00
23 alpha_raw_site[15]  1.00
24 alpha_raw_site[16]  1.00
25 alpha_raw_site[17]  1.00
26 alpha_raw_site[18]  1.00
27 alpha_raw_site[19]  1.00
28 alpha_raw_site[20]  1.00
29 alpha_raw_site[21]  1.00
30 alpha_raw_site[22]  1.00
31 alpha_raw_site[23]  1.00
32 sigma_year          1.00
33 sigma_site          1.00
34 lp__                1.00</code></pre>
</div>
</div>
<p><em>Relationship with temperature</em></p>
<p>The plot below compares prior to posterior predictions of the relationship between mean annual temperature and <span class="math inline">\(b\)</span> exponents. The difference in the spread of the lines is a proxy indicator of how much information was learned from the data.</p>
<div class="cell" data-paged.print="false">
<div class="cell-output-display">
<p><img src="stan_spectra_manuscript_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The table below shows the parameter estimates of the intercept and slope (beta). As with previous analyses, beta is small with wide variation indicating a 95% probability of being between -0.04 and 0.02. Because these values are based on standardized estimates, they suggest that across the entire range of temperatures, <span class="math inline">\(b\)</span> changes by less than about 0.1 absolute units, a minimal change. The slope is slightly more negative than positive, but with only a 74% probability of being negative.</p>
<div class="cell" data-paged.print="false">
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 7
  name    value  .lower  .upper .width .point .interval
  &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    
1 a     -1.30   -1.34   -1.26     0.95 median qi       
2 beta  -0.0112 -0.0442  0.0232   0.95 median qi       </code></pre>
</div>
</div>
<p><em>Variation among sites</em></p>
<p>Using the varying intercepts, we can make predictions of the mean <span class="math inline">\(b\)</span> for individual sites. The plot below shows those predictions along with dots generated from a previous analysis using the MLE method in sizeSpectra. (NOTE: dots need to be updated with current data that has been fixed for no_m2 sums).</p>
<div class="cell" data-paged.print="false">
<div class="cell-output-display">
<p><img src="stan_spectra_manuscript_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><em>Which contributes the most to residual variation (year or sites)?</em></p>
<p>Comparing the varying intercept standard deviations demonstrates which of the groupings (site versus year) contributes most to residual variation in <span class="math inline">\(b\)</span>. The plot below shows that sites contribute ~2x more variation. The have an sd of 0.8, indicating that an average site is +/- 0.8 units from the intercept value of -1.3. By contrast, variation among years is about 0.3.</p>
<div class="cell" data-paged.print="false">
<div class="cell-output-display">
<p><img src="stan_spectra_manuscript_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><em>Posterior predictive checks</em></p>
<p>TBD</p>
<p><strong>Supplementary Information</strong></p>
<ol type="1">
<li><p>Run model on simulated data and ensure that parameters are recovered (they are, just need to add)</p></li>
<li><p>Run model in individual sites and compare with results from sizeSpectra package</p></li>
<li><p>Derive posterior predictive equation. The current method works, but may not capture the influence of counts (no_m2) correctly. Need help on this.</p></li>
</ol>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>